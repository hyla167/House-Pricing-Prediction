{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10762360,"sourceType":"datasetVersion","datasetId":6675603}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# In[1]: PART 1. IMPORT AND FUNCTIONS\n#region\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer  \nfrom sklearn.preprocessing import OneHotEncoder      \nfrom statistics import mean\nfrom sklearn.model_selection import KFold   \nimport joblib\n# In[2]: PART 2. GET THE DATA \nraw_data = pd.read_csv('/kaggle/input/vn-housing-dataset/VN_housing_dataset_processed1.csv')\n\n# In[3]: PART 3. DISCOVER THE DATA \n#region\n# 3.1 Quick view of the data\nprint('\\n____________ Dataset info ____________')\nprint(raw_data.info())              \nprint('\\n____________ Statistics of numeric features ____________')\nprint(raw_data.describe()) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:02:35.263523Z","iopub.execute_input":"2025-02-16T16:02:35.263780Z","iopub.status.idle":"2025-02-16T16:02:38.635371Z","shell.execute_reply.started":"2025-02-16T16:02:35.263757Z","shell.execute_reply":"2025-02-16T16:02:38.633976Z"}},"outputs":[{"name":"stdout","text":"\n____________ Dataset info ____________\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 80773 entries, 0 to 80772\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Quận             80772 non-null  object \n 1   Huyện            80733 non-null  object \n 2   Loại hình nhà ở  80744 non-null  object \n 3   Giấy tờ pháp lý  52430 non-null  object \n 4   Số tầng          35667 non-null  float64\n 5   Số phòng ngủ     80735 non-null  float64\n 6   Diện tích        80773 non-null  float64\n 7   Dài (m)          19294 non-null  float64\n 8   Rộng (m)         34526 non-null  float64\n 9   Giá (triệu/m2)   80773 non-null  float64\ndtypes: float64(6), object(4)\nmemory usage: 6.2+ MB\nNone\n\n____________ Statistics of numeric features ____________\n            Số tầng  Số phòng ngủ     Diện tích        Dài (m)       Rộng (m)  \\\ncount  35667.000000  80735.000000  80773.000000   19294.000000   34526.000000   \nmean       4.433426      3.804967     47.051077      91.033516      38.455521   \nstd        1.519723      1.311443     60.638021    6557.390338    3142.382711   \nmin        1.000000      1.000000      2.000000       1.000000       1.000000   \n25%        4.000000      3.000000     34.000000       8.000000       3.900000   \n50%        5.000000      4.000000     40.000000      10.000000       4.000000   \n75%        5.000000      4.000000     50.000000      12.000000       5.000000   \nmax       73.000000     10.000000  10360.000000  900000.000000  423432.000000   \n\n       Giá (triệu/m2)  \ncount    80773.000000  \nmean       101.711335  \nstd         61.602630  \nmin          1.000000  \n25%         73.130000  \n50%         89.710000  \n75%        110.000000  \nmax        990.000000  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# View unique values of categorical features\nprint(raw_data['Quận'].unique())\nprint(raw_data['Huyện'].unique())\nprint(raw_data['Loại hình nhà ở'].unique())\nprint(raw_data['Giấy tờ pháp lý'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:02:45.767143Z","iopub.execute_input":"2025-02-16T16:02:45.767548Z","iopub.status.idle":"2025-02-16T16:02:45.784737Z","shell.execute_reply.started":"2025-02-16T16:02:45.767520Z","shell.execute_reply":"2025-02-16T16:02:45.783568Z"}},"outputs":[{"name":"stdout","text":"['Quận Cầu Giấy' 'Quận Thanh Xuân' 'Quận Hai Bà Trưng' 'Quận Tây Hồ'\n 'Quận Đống Đa' 'Quận Hà Đông' 'Huyện Thanh Trì' 'Quận Hoàng Mai'\n 'Quận Long Biên' 'Quận Nam Từ Liêm' 'Quận Ba Đình' 'Huyện Hoài Đức'\n 'Quận Bắc Từ Liêm' 'Huyện Đan Phượng' 'Huyện Thanh Oai' 'Huyện Sóc Sơn'\n 'Huyện Gia Lâm' 'Huyện Chương Mỹ' 'Quận Hoàn Kiếm' 'Huyện Đông Anh'\n 'Huyện Thường Tín' 'Thị xã Sơn Tây' 'Huyện Mê Linh' 'Huyện Thạch Thất'\n 'Huyện Quốc Oai' 'Huyện Phúc Thọ' 'Huyện Phú Xuyên' 'Huyện Ba Vì' nan\n 'Huyện Mỹ Đức']\n['Phường Nghĩa Đô' 'Phường Kim Giang' 'Phường Minh Khai'\n 'Phường Thụy Khuê' 'Phường Trung Liệt' 'Phường Đống Mác' 'Phường Xuân La'\n 'Phường Văn Quán' 'Thị trấn Văn Điển' 'Phường Định Công' 'Phường Bồ Đề'\n 'Phường Quang Trung' 'Phường Thanh Lương' 'Phường Khương Trung'\n 'Phường Gia Thụy' 'Phường Khương Đình' 'Phường Phương Canh'\n 'Phường Tương Mai' 'Phường La Khê' 'Phường Mễ Trì' 'Phường Khương Mai'\n 'Phường Láng Hạ' 'Phường Quan Hoa' 'Phường Tây Mỗ' 'Phường Ngọc Khánh'\n 'Phường Đại Mỗ' 'Xã Tả Thanh Oai' 'Phường Mỹ Đình 1' 'Xã Tam Hiệp'\n 'Phường Cống Vị' 'Phường Bách Khoa' 'Phường Vĩnh Phúc' 'Xã Kim Chung'\n 'Phường Đại Kim' 'Phường Mai Động' 'Phường Trung Tự' 'Phường Kiến Hưng'\n 'Phường Trúc Bạch' 'Phường Cổ Nhuế 1' 'Phường Đức Giang'\n 'Phường Mỹ Đình 2' 'Phường Bưởi' 'Phường Ô Chợ Dừa' 'Phường Long Biên'\n 'Phường Hoàng Văn Thụ' 'Phường Mai Dịch' 'Phường Nhân Chính'\n 'Phường Vạn Phúc' 'Phường Ngọc Hà' 'Phường Lĩnh Nam' 'Phường Xuân Đỉnh'\n 'Phường Phú Đô' 'Phường Liễu Giai' 'Thị trấn Phùng' 'Phường Kim Liên'\n 'Phường Phúc Diễn' 'Phường Kim Mã' 'Phường Trung Phụng' 'Phường Tân Mai'\n 'Phường Ngã Tư Sở' 'Phường Trung Văn' 'Phường Thượng Đình'\n 'Phường Hoàng Liệt' 'Phường Thịnh Liệt' 'Phường Quốc Tử Giám'\n 'Phường Khâm Thiên' 'Phường Trương Định' 'Phường Phú Diễn'\n 'Phường Thạch Bàn' 'Phường Ngọc Thụy' 'Phường Cầu Dền' 'Phường Phú Lương'\n 'Phường Bạch Đằng' 'Phường Phú La' 'Phường Hà Cầu' 'Phường Láng Thượng'\n 'Phường Phương Liệt' 'Phường Vĩnh Hưng' 'Phường Thanh Nhàn'\n 'Phường Cự Khối' 'Phường Đội Cấn' 'Phường Thịnh Quang' 'Phường Trung Hoà'\n 'Phường Quỳnh Mai' 'Phường Nam Đồng' 'Phường Dịch Vọng Hậu'\n 'Phường Nghĩa Tân' 'Xã Cự Khê' 'Phường Yên Hoà' 'Phường Vĩnh Tuy'\n 'Phường Quảng An' 'Phường Yên Nghĩa' 'Phường Thành Công'\n 'Phường Giáp Bát' 'Phường Dịch Vọng' 'Phường Thanh Xuân Bắc'\n 'Phường Phương Mai' 'Phường Bạch Mai' 'Phường Thanh Trì'\n 'Phường Thượng Thanh' 'Phường Trần Phú' 'Phường Nguyễn Trãi'\n 'Phường Dương Nội' 'Phường Hạ Đình' 'Phường Thanh Xuân Nam' 'Xã Vân Canh'\n nan 'Xã Phù Lỗ' 'Phường Phố Huế' 'Phường Đồng Tâm' 'Phường Xuân Phương'\n 'Phường Phạm Đình Hổ' 'Xã La Phù' 'Phường Ngọc Lâm' 'Phường Mộ Lao'\n 'Phường Phú Thượng' 'Phường Việt Hưng' 'Phường Đông Ngạc'\n 'Phường Thổ Quan' 'Phường Lê Đại Hành' 'Phường Khương Thượng'\n 'Phường Cầu Diễn' 'Phường Phú Lãm' 'Xã Cổ Bi' 'Phường Biên Giang'\n 'Phường Hàng Bột' 'Phường Cổ Nhuế 2' 'Phường Giảng Võ'\n 'Thị trấn Chúc Sơn' 'Xã Kiêu Kỵ' 'Phường Cát Linh' 'Phường Quỳnh Lôi'\n 'Phường Yên Sở' 'Xã Đặng Xá' 'Phường Yết Kiêu' 'Phường Cửa Đông'\n 'Phường Giang Biên' 'Phường Chương Dương' 'Phường Phúc La'\n 'Phường Phúc Đồng' 'Phường Thượng Cát' 'Phường Phúc Xá'\n 'Phường Văn Chương' 'Xã Tứ Hiệp' 'Xã Đông Dư' 'Phường Thanh Xuân Trung'\n 'Phường Phương Liên' 'Phường Nhật Tân' 'Thị trấn Trạm Trôi'\n 'Phường Sài Đồng' 'Xã Tân Triều' 'Phường Văn Miếu' 'Xã Đông Hội'\n 'Xã Phụng Châu' 'Thị trấn Trâu Quỳ' 'Phường Quán Thánh' 'Phường Phúc Lợi'\n 'Xã Hữu Hoà' 'Phường Đồng Nhân' 'Phường Ngô Thì Nhậm' 'Phường Đồng Mai'\n 'Xã Đông La' 'Phường Liên Mạc' 'Xã Ngọc Hồi' 'Phường Bùi Thị Xuân'\n 'Phường Xuân Tảo' 'Phường Yên Phụ' 'Xã Thanh Liệt' 'Phường Thụy Phương'\n 'Phường Hàng Bông' 'Xã Nghiêm Xuyên' 'Phường Nguyễn Du' 'Phường Tứ Liên'\n 'Phường Phan Chu Trinh' 'Xã Vĩnh Quỳnh' 'Phường Cửa Nam' 'Xã Di Trạch'\n 'Xã Võng La' 'Phường Điện Biên' 'Xã Bắc Hồng' 'Xã Hải Bối' 'Xã Đại Yên'\n 'Phường Ngô Quyền' 'Phường Phúc Tân' 'Phường Trần Hưng Đạo'\n 'Xã Liên Ninh' 'Phường Hàng Bài' 'Xã Đông Mỹ' 'Phường Đức Thắng'\n 'Phường Tràng Tiền' 'Phường Hàng Bạc' 'Xã Ngũ Hiệp' 'Xã An Thượng'\n 'Xã Yên Thường' 'Xã Duyên Hà' 'Phường Đồng Xuân' 'Xã An Khánh'\n 'Thị trấn Yên Viên' 'Phường Hàng Buồm' 'Xã Lại Yên' 'Xã Bích Hòa'\n 'Thị trấn Quang Minh' 'Thị trấn Kim Bài' 'Xã Khánh Hà' 'Phường Tây Tựu'\n 'Xã Thủy Xuân Tiên' 'Xã Kim Nỗ' 'Xã Tân Lập' 'Xã Đại Thịnh'\n 'Phường Hàng Mã' 'Xã Bình Yên' 'Xã Vạn Phúc' 'Xã Phú Cường' 'Xã Đa Tốn'\n 'Phường Hàng Bồ' 'Xã Minh Phú' 'Phường Nguyễn Trung Trực'\n 'Phường Lý Thái Tổ' 'Thị trấn Quốc Oai' 'Phường Phú Thịnh' 'Xã Đại áng'\n 'Xã Võng Xuyên' 'Xã Phú Mãn' 'Thị trấn Phú Xuyên' 'Xã Hà Hồi'\n 'Xã Phú Châu' 'Xã Cổ Đông' 'Xã Vân Côn' 'Xã Xuân Giang' 'Xã Tam Đồng'\n 'Xã Dương Quang' 'Thị trấn Đông Anh' 'Xã Đông Yên' 'Xã Vân Nội'\n 'Xã Tiên Dược' 'Xã Hương Ngải' 'Xã Hoàng Văn Thụ' 'Xã Ngọc Liệp'\n 'Xã Nhị Khê' 'Thị trấn Xuân Mai' 'Xã Bát Tràng' 'Phường Hàng Đào'\n 'Xã Thạch Hoà' 'Xã Tam Hưng' 'Xã Nguyên Khê' 'Xã Sài Sơn' 'Xã Ninh Hiệp'\n 'Xã Uy Nỗ' 'Phường Viên Sơn' 'Thị trấn Thường Tín' 'Xã Ninh Sở'\n 'Xã Phương Trung' 'Xã Vĩnh Ngọc' 'Xã Kim Sơn' 'Xã Minh Khai' 'Xã Phú Cát'\n 'Xã Duyên Thái' 'Xã Vân Hòa' 'Phường Trung Sơn Trầm' 'Xã Dương Xá'\n 'Xã Xuân Nộn' 'Xã Sơn Đông' 'Xã Văn Bình' 'Phường Hàng Gai'\n 'Xã Thanh Cao' 'Xã Mai Đình' 'Xã Đông Xuân' 'Xã Mai Lâm' 'Xã Sơn Đồng'\n 'Xã Tân Xã' 'Phường Xuân Khanh' 'Xã Thượng Mỗ' 'Xã Nghĩa Hương'\n 'Xã Dương Liễu' 'Xã Nam Hồng' 'Xã Đức Thượng' 'Phường Hàng Trống'\n 'Xã Kim Hoa' 'Xã Tiền Phong' 'Xã Bình Phú' 'Xã Dục Tú' 'Xã Đức Giang'\n 'Xã Yên Viên' 'Xã Đồng Quang' 'Xã Quang Tiến' 'Xã Đại Thành'\n 'Xã Hòa Thạch' 'Xã Tiến Xuân' 'Xã Phù Linh' 'Xã Đỗ Động' 'Xã Phú Minh'\n 'Xã Tiên Dương' 'Xã Hợp Thanh' 'Xã Minh Trí' 'Xã Tân Hội' 'Xã Thanh Xuân'\n 'Xã Song Phương' 'Xã Lê Lợi' 'Thị trấn Sóc Sơn' 'Thị trấn Liên Quan'\n 'Xã Mê Linh' 'Xã Đan Phượng' 'Xã Vân Tảo' 'Xã Đình Xuyên' 'Xã Phù Đổng'\n 'Xã Phú Sơn' 'Xã Ngọc Tảo' 'Xã Phương Đình']\n['Nhà ngõ, hẻm' 'Nhà mặt phố, mặt tiền' 'Nhà biệt thự' 'Nhà phố liền kề'\n nan]\n['Đã có sổ' nan 'Đang chờ sổ' 'Giấy tờ khác']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# In[4]: PART 4. PREPARE THE DATA \n# 4.2 Split training-test sets\nfrom sklearn.model_selection import train_test_split\n\n# 4.4 Define pipelines for processing data. \n# Define ColumnSelector: a transformer for choosing columns:\nclass ColumnSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, feature_names):\n        self.feature_names = feature_names\n    def fit(self, dataframe, labels=None):\n        return self\n    def transform(self, dataframe):\n        return dataframe[self.feature_names].values    \ncat_feat_names = ['Quận', 'Huyện', 'Loại hình nhà ở', 'Giấy tờ pháp lý'] \nnum_feat_names = ['Số tầng', 'Số phòng ngủ', 'Diện tích', 'Dài (m)', 'Rộng (m)'] \n\n# Pipeline for categorical features:\ncat_pipeline = Pipeline([\n    ('selector', ColumnSelector(cat_feat_names)),\n    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value = \"NO INFO\", copy=True)),\n    ('cat_encoder', OneHotEncoder(handle_unknown=\"ignore\")) ])    \n\n# Pipeline for numerical features:\nnum_pipeline = Pipeline([\n    ('selector', ColumnSelector(num_feat_names)),\n    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"median\", copy=True)),  \n    ('std_scaler', StandardScaler(with_mean=True, with_std=True, copy=True)) ])  \n  \n# Combine features transformed by two above pipelines:\nfull_pipeline = FeatureUnion(transformer_list=[\n    (\"num_pipeline\", num_pipeline),\n    (\"cat_pipeline\", cat_pipeline) ])  \n\n# Define the target column (adjust 'target_col' to match the actual label column in your dataset)\ntarget_col = \"Giá (triệu/m2)\"  # Change this to the actual target variable\n\n# Split features (X) and target labels (y)\nX = raw_data.drop(columns=[target_col])  # Features\ny = raw_data[target_col]  # Labels\n\n# Create train and test sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Apply preprocessing pipeline\nX_train_processed = full_pipeline.fit_transform(X_train)\nX_test_processed = full_pipeline.transform(X_test)\nprint('\\n____________ Processed feature values ____________')\nprint(X_train_processed[[0, 1, 2],:].toarray())\nprint(X_train_processed.shape)\n# print('We have %d numeric feature + 1 added features + 35 cols of onehotvector for categorical features.' %(len(num_feat_names)))\njoblib.dump(full_pipeline, r'/kaggle/working/full_pipeline.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:03:31.294915Z","iopub.execute_input":"2025-02-16T16:03:31.295232Z","iopub.status.idle":"2025-02-16T16:03:31.599503Z","shell.execute_reply.started":"2025-02-16T16:03:31.295209Z","shell.execute_reply":"2025-02-16T16:03:31.598417Z"}},"outputs":[{"name":"stdout","text":"\n____________ Processed feature values ____________\n[[ 0.22792003 -0.612713   -0.24432111 -0.00628668 -0.00708703  0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          1.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          1.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          1.          0.          0.          0.          0.\n   0.          1.        ]\n [ 0.22792003 -0.612713    0.10451527 -0.00600744 -0.00708703  0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          1.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          1.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          1.          0.          0.          0.\n   0.          1.        ]\n [-0.68418356  0.15318418 -0.28536068 -0.00628668 -0.00752252  0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          1.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   1.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          1.          0.          0.          0.\n   0.          1.        ]]\n(64618, 332)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/full_pipeline.pkl']"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# In[5]: PART 5. TRAIN AND EVALUATE MODELS \n#region\n# 5.1 Try LinearRegression model\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train_processed, y_train)\nprint('\\n____________ LinearRegression ____________')\nprint('Learned parameters: ', model.coef_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:03:55.239651Z","iopub.execute_input":"2025-02-16T16:03:55.240045Z","iopub.status.idle":"2025-02-16T16:03:56.381372Z","shell.execute_reply.started":"2025-02-16T16:03:55.240013Z","shell.execute_reply":"2025-02-16T16:03:56.379752Z"}},"outputs":[{"name":"stdout","text":"\n____________ LinearRegression ____________\nLearned parameters:  [ 3.11802432e+00  7.93330291e+00 -9.15711421e-01 -1.03494865e-01\n  1.70674879e-01 -4.67527378e+01 -4.04974805e+01 -1.10753955e+01\n -1.30549128e+01 -5.11631831e+01 -3.73547071e+01 -1.90570066e+01\n  8.41356549e+00 -5.14783639e+01 -4.13037429e+01  2.84492872e+01\n -3.25562020e+01 -6.15644830e+01 -4.63715643e+01 -1.54624404e+01\n -2.10630674e+00  2.00522537e+01  5.53493287e+01  4.64221083e+01\n  2.18891153e+02  3.35857066e+00  6.25914290e-01 -4.38697418e+00\n  6.10529513e+00  5.55978420e+01  6.38373582e+01  3.59473565e+01\n -6.88645324e+01 -2.14320309e+01 -4.10474098e+01 -1.12957042e+01\n  1.58596111e+02 -1.09721714e+01 -1.89094781e+01 -1.32409335e+01\n  2.64146571e+01 -1.93051140e+02  1.59115131e+01  2.09997440e+01\n -8.56783206e+00  5.50649549e+01 -3.55588205e+00 -3.60797457e+00\n -7.55936863e+01 -6.18839466e+01 -6.16103512e-01 -8.22812421e+00\n -9.06462003e+00 -5.70910604e+00  2.67059852e+01 -1.66999362e+01\n  1.80086750e+01  6.20354351e+01  5.60791104e+00  1.65030182e+01\n  5.01712554e+00  1.10573735e+02 -2.26322457e+01  1.44901154e+02\n  6.16075834e+01  2.66522849e+01  5.48342967e+00 -7.98110214e+01\n -1.89383648e+00  3.13018672e+02  1.99699896e+01 -2.24256093e+01\n -7.11549703e+00 -1.73402483e+01  4.78427276e+00 -2.57492149e+01\n -3.22591485e+01 -3.77645430e+01  1.01308854e+01  5.21759472e+01\n -1.47445101e+00  4.63547198e+00 -3.93316471e+01  7.34334790e+01\n  1.68304996e+01  2.10392190e+01  8.43952142e+00  7.91895572e+01\n  2.12285591e+02  3.94204341e+00 -1.64376089e+01  1.49871966e+01\n -2.04332541e+01  2.21123289e+01  1.57904622e+01  2.12337594e+01\n  2.34401956e+01  2.00882332e+01 -4.22929230e+00 -1.20708231e+01\n  1.13783524e+02  2.24236384e+02  3.08571588e+01  2.13695529e+00\n  3.07402584e+01  1.05602688e+02  4.38389704e+01  5.73179502e+01\n  2.48725892e+01  7.40901443e+00 -2.26226814e+01 -7.56869319e+00\n -2.81391950e+00 -1.84773488e+01 -1.87096877e-01 -1.18180410e+01\n -1.45951747e+01 -4.54679608e+01  1.79943491e+01  2.35348087e+01\n -2.87923856e+01  1.23589471e+01 -7.45339441e+00 -1.92644489e+02\n  3.55080809e+01  8.29502392e+00 -4.99283202e+00  3.60646988e+00\n -1.49589262e+01  7.70007280e+00  2.36869603e+01  4.40224125e+01\n -1.48166732e+01  9.78043548e+00  1.53487469e+02  1.57959791e+01\n  7.89773506e+00 -1.47576144e+01 -8.98567879e+00 -1.36685461e-01\n -1.56100116e+01 -1.33160368e+01  2.60360623e+00 -2.53522779e+01\n -3.73196409e+01 -1.12338928e+01  5.43927641e+01 -2.79965029e+01\n  1.53715190e+00 -2.38195470e+01  4.52083059e+00  1.46564021e+01\n  6.21908341e+00  1.79316607e+00 -1.47910852e+01 -2.64368226e+01\n  8.42823950e+00  2.73010843e+01  1.83392265e+00 -1.24704125e+01\n -1.62487020e+00  1.31680704e+01  1.28147568e+01  2.04902504e+02\n -2.56101332e+01 -4.85152674e+01 -1.24607084e+00  1.70030806e+01\n -1.10052402e+01 -2.63526570e+01  1.78057684e+01 -3.81572040e+01\n  3.45480118e+01  4.73784257e+00  2.23388631e+00  1.55343066e+01\n  1.19208581e+01  1.85295854e-01  4.13073309e+01 -1.19365165e+01\n  1.45053008e+01  2.67167648e+01 -2.89111251e+01 -9.96163920e-01\n -1.12246339e+01 -6.35325409e+00 -1.54829822e+01 -1.84158574e+01\n -7.97623237e+00  1.05833974e+01 -4.93923890e+00  2.48372573e+01\n  1.55255889e+02 -3.84720461e+01  1.68742832e+01 -6.56232440e+00\n  1.16394690e+01 -7.99182400e+00 -2.47730210e+01 -3.02311126e+00\n -1.32141404e+01 -4.09306102e+00  4.48224534e+01  4.14667074e+00\n -4.09134668e+01 -3.15393154e+01  1.46536738e-01  1.48821694e+01\n -1.23784072e+01 -3.03538251e+01 -5.56871559e+00  4.52826063e-01\n -1.19268473e+00 -3.20451462e+01 -3.82348262e+01 -2.21451950e+01\n -2.39287339e+01 -2.02533684e+01 -1.49730145e+01 -1.21016522e+01\n  1.08467799e+01 -1.16046321e+01  7.03660619e-01  1.76054507e+01\n -4.56647595e+01 -1.04528394e+01  2.12247849e+01  2.22163465e+01\n -4.71201422e+00 -3.84126248e+01 -2.71016148e+01  2.28256227e+00\n -3.61181030e+01  4.10941670e+00 -1.36876270e+01 -3.73547071e+01\n -3.77455976e+01  3.36695455e+00  8.92642530e+00 -2.00568634e+01\n -2.54078308e+01 -1.83482875e+01 -1.41761960e+00 -5.25986903e+01\n  6.45664499e+00  1.38835497e+01 -1.14196407e+01  1.00254869e+01\n -1.22564369e+01  2.65901085e+01 -3.34343434e+01 -4.63496906e+01\n -5.95761348e+01 -2.50232160e+01 -6.27193827e+01 -3.43250736e+01\n -9.26238529e+01 -1.90570066e+01  1.14293695e+01  3.02214949e+01\n -3.57696443e+01 -1.55610522e+01 -4.15644682e-01 -6.93119977e+00\n -1.26464632e+01 -5.64527944e+01 -7.43115714e+00 -1.80466053e+01\n -6.65956359e+01 -4.49009356e+01 -1.87019759e+00 -3.97220998e+00\n -9.24340492e+00 -6.73102511e+01  4.59207206e+01  1.44495355e+01\n -4.20153953e+01  6.14381030e+00 -3.19197451e+01 -4.46300892e+01\n -2.67596368e+01  1.87833807e-01 -5.94984374e+01 -7.12593813e+00\n  5.11280090e+01  4.68764567e+00  1.76113095e-01  2.21976769e+01\n  4.39315971e+00 -1.88053857e+01 -5.85958559e+01 -4.20664230e+01\n -2.75551947e+01  4.12406823e+00  6.08866601e+00 -5.40103115e+00\n  1.07946611e+01 -2.84740229e+01 -3.16826462e+01  2.75677017e+01\n -1.65763666e+01 -5.22076852e+01 -5.95519790e+01 -5.90683680e+01\n -3.37561471e+01 -3.19262034e+01 -1.15074847e+01 -1.08555639e+00\n -6.15258817e+01 -8.34130598e+00 -1.58093887e+01 -3.67868290e+00\n -6.80094919e+01 -3.87785506e+00  4.17677339e+02 -6.11363888e+01\n -2.44061466e+01  1.71592399e+01 -6.28302675e+01 -2.75450284e+01\n -4.09156004e+01 -4.70637658e+01 -2.62022258e+00  6.98371602e-01\n  6.58409148e+00  1.94757998e+01 -2.61870008e+01 -5.71261660e-01\n -1.62559175e+01  9.88536157e+00 -5.44649290e+00  1.18170488e+01]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Compute R2 score and root mean squared error\ndef r2score_and_rmse(model, train_data, labels): \n    r2score = model.score(train_data, labels)\n    from sklearn.metrics import mean_squared_error\n    prediction = model.predict(train_data)\n    mse = mean_squared_error(labels, prediction)\n    rmse = np.sqrt(mse)\n    return r2score, rmse      \nr2score, rmse = r2score_and_rmse(model, X_train_processed, y_train)\nprint('\\nR2 score (on training data, best=1):', r2score)\nprint(\"Root Mean Square Error: \", rmse.round(decimals=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:04:12.481110Z","iopub.execute_input":"2025-02-16T16:04:12.481624Z","iopub.status.idle":"2025-02-16T16:04:12.499499Z","shell.execute_reply.started":"2025-02-16T16:04:12.481580Z","shell.execute_reply":"2025-02-16T16:04:12.498451Z"}},"outputs":[{"name":"stdout","text":"\nR2 score (on training data, best=1): 0.331349434853627\nRoot Mean Square Error:  50.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Predict labels for some training instances:\nprint(\"\\nInput data: \\n\", X_train.iloc[0:9])\nprint(\"\\nPredictions: \", model.predict(X_train_processed[0:9]).round(decimals=1))\nprint(\"Labels:      \", list(y_train[0:9]))\n\n# Store models to files, to compare latter:\ndef store_model(model, model_name = \"\"):\n    if model_name == \"\": \n        model_name = type(model).__name__\n    joblib.dump(model,'/kaggle/working/' + model_name + '_model.pkl')\ndef load_model(model_name):\n    model = joblib.load('/kaggle/working/' + model_name + '_model.pkl')\n    return model\nstore_model(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:04:37.886207Z","iopub.execute_input":"2025-02-16T16:04:37.886626Z","iopub.status.idle":"2025-02-16T16:04:37.906273Z","shell.execute_reply.started":"2025-02-16T16:04:37.886598Z","shell.execute_reply":"2025-02-16T16:04:37.904972Z"}},"outputs":[{"name":"stdout","text":"\nInput data: \n                     Quận                Huyện        Loại hình nhà ở  \\\n57914       Quận Đống Đa  Phường Quốc Tử Giám  Nhà mặt phố, mặt tiền   \n47549   Quận Nam Từ Liêm     Phường Mỹ Đình 1           Nhà ngõ, hẻm   \n13623       Quận Hà Đông      Phường Vạn Phúc           Nhà ngõ, hẻm   \n2262      Quận Hoàng Mai      Phường Mai Động           Nhà ngõ, hẻm   \n4389        Quận Đống Đa     Phường Ô Chợ Dừa           Nhà ngõ, hẻm   \n61604  Quận Hai Bà Trưng      Phường Vĩnh Tuy           Nhà ngõ, hẻm   \n77455    Quận Thanh Xuân    Phường Nhân Chính  Nhà mặt phố, mặt tiền   \n54998    Quận Thanh Xuân   Phường Khương Đình           Nhà ngõ, hẻm   \n45546     Quận Hoàng Mai      Phường Lĩnh Nam           Nhà ngõ, hẻm   \n\n      Giấy tờ pháp lý  Số tầng  Số phòng ngủ  Diện tích  Dài (m)  Rộng (m)  \n57914        Đã có sổ      NaN           3.0       35.0      NaN       5.0  \n47549        Đã có sổ      NaN           3.0       52.0     11.0       5.0  \n13623        Đã có sổ      4.0           4.0       33.0      NaN       NaN  \n2262         Đã có sổ      5.0           3.0       45.0      NaN       NaN  \n4389         Đã có sổ      NaN           8.0       66.0      NaN       NaN  \n61604             NaN      NaN           4.0       48.0      NaN       NaN  \n77455             NaN      NaN           8.0       56.0      NaN       NaN  \n54998        Đã có sổ      4.0           4.0       49.0      NaN       NaN  \n45546        Đã có sổ      NaN           3.0       33.0      NaN       NaN  \n\nPredictions:  [147.2  84.7  76.1  75.9 148.3  96.1 164.4  84.   65.1]\nLabels:       [351.43, 94.23, 69.7, 84.44, 75.76, 93.75, 464.29, 78.57, 71.21]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#%% 5.2 Try DecisionTreeRegressor model\n# Training:\nfrom sklearn.tree import DecisionTreeRegressor\nmodel = DecisionTreeRegressor()\nmodel.fit(X_train_processed, y_train)\n# Compute R2 score and root mean squared error:\nprint('\\n____________ DecisionTreeRegressor ____________')\nr2score, rmse = r2score_and_rmse(model, X_train_processed, y_train)\nprint('\\nR2 score (on training data, best=1):', r2score)\nprint(\"Root Mean Square Error: \", rmse.round(decimals=1))\nstore_model(model)\n# Predict labels for some training instances:\nprint(\"\\nPredictions: \", model.predict(X_train_processed[0:9]).round(decimals=1))\nprint(\"Labels:      \", list(y_train[0:9]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:05:22.621130Z","iopub.execute_input":"2025-02-16T16:05:22.621542Z","iopub.status.idle":"2025-02-16T16:05:30.836653Z","shell.execute_reply.started":"2025-02-16T16:05:22.621510Z","shell.execute_reply":"2025-02-16T16:05:30.835504Z"}},"outputs":[{"name":"stdout","text":"\n____________ DecisionTreeRegressor ____________\n\nR2 score (on training data, best=1): 0.9345191317243118\nRoot Mean Square Error:  15.7\n\nPredictions:  [351.4  94.2  69.7  84.4  75.8  87.2 464.3  78.1  75.1]\nLabels:       [351.43, 94.23, 69.7, 84.44, 75.76, 93.75, 464.29, 78.57, 71.21]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#%% 5.3 Try RandomForestRegressor model\n# Training:\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators = 5) \nmodel.fit(X_train_processed, y_train)\n# Compute R2 score and root mean squared error:\nprint('\\n____________ RandomForestRegressor ____________')\nr2score, rmse = r2score_and_rmse(model, X_train_processed, y_train)\nprint('\\nR2 score (on training data, best=1):', r2score)\nprint(\"Root Mean Square Error: \", rmse.round(decimals=1))\nstore_model(model)      \n# Predict labels for some training instances:\nprint(\"\\nPredictions: \", model.predict(X_train_processed[0:9]).round(decimals=1))\nprint(\"Labels:      \", list(y_train[0:9]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T07:13:43.060648Z","iopub.execute_input":"2025-02-16T07:13:43.060997Z","iopub.status.idle":"2025-02-16T07:14:03.836310Z","shell.execute_reply.started":"2025-02-16T07:13:43.060971Z","shell.execute_reply":"2025-02-16T07:14:03.835343Z"}},"outputs":[{"name":"stdout","text":"\n____________ RandomForestRegressor ____________\n\nR2 score (on training data, best=1): 0.8210227948958359\nRoot Mean Square Error:  25.9\n\nPredictions:  [307.8  95.8  73.3  75.4 127.4  91.4 401.8  78.3  74.1]\nLabels:       [351.43, 94.23, 69.7, 84.44, 75.76, 93.75, 464.29, 78.57, 71.21]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import optuna\nfrom sklearn.metrics import mean_squared_error\n# full_pipeline = joblib.load(r'/kaggle/working/full_pipeline.pkl')\n# processed_test_set = full_pipeline.transform(test_set)\ndef objective(trial):\n    params = {\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n    }\n    model = XGBRegressor(**params)\n    model.fit(X_train_processed, y_train)\n    y_pred = model.predict(X_test_processed)\n    return mean_squared_error(y_test, y_pred, squared=False)\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\n\nprint(\"Best parameters:\", study.best_params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:48:38.122714Z","iopub.execute_input":"2025-02-16T08:48:38.123075Z","iopub.status.idle":"2025-02-16T08:50:28.642747Z","shell.execute_reply.started":"2025-02-16T08:48:38.123045Z","shell.execute_reply":"2025-02-16T08:50:28.640752Z"}},"outputs":[{"name":"stderr","text":"[I 2025-02-16 08:48:38,125] A new study created in memory with name: no-name-b925f860-bb5f-42e6-8b07-fec62b4e5ecd\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:39,889] Trial 0 finished with value: 47.59672180208266 and parameters: {'learning_rate': 0.06849176390117735, 'max_depth': 7, 'n_estimators': 406, 'subsample': 0.6007580807035985, 'colsample_bytree': 0.6767759178062509}. Best is trial 0 with value: 47.59672180208266.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:42,665] Trial 1 finished with value: 47.43443628392234 and parameters: {'learning_rate': 0.0739621914712462, 'max_depth': 9, 'n_estimators': 488, 'subsample': 0.6037198282907026, 'colsample_bytree': 0.6561189217693149}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:43,272] Trial 2 finished with value: 48.54793657490188 and parameters: {'learning_rate': 0.10649757755620522, 'max_depth': 4, 'n_estimators': 261, 'subsample': 0.5732188876865285, 'colsample_bytree': 0.519028192391426}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:43,930] Trial 3 finished with value: 50.99825601081804 and parameters: {'learning_rate': 0.015065174800282884, 'max_depth': 8, 'n_estimators': 102, 'subsample': 0.9480136862413888, 'colsample_bytree': 0.7701143064724375}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:47,002] Trial 4 finished with value: 47.81924662149462 and parameters: {'learning_rate': 0.04861533976014649, 'max_depth': 7, 'n_estimators': 438, 'subsample': 0.8658117843537385, 'colsample_bytree': 0.918771069553112}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:47,738] Trial 5 finished with value: 49.03833647093608 and parameters: {'learning_rate': 0.12037210470686158, 'max_depth': 3, 'n_estimators': 367, 'subsample': 0.698614241772149, 'colsample_bytree': 0.7995115785264968}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:48,851] Trial 6 finished with value: 50.07524192963785 and parameters: {'learning_rate': 0.018899642901850224, 'max_depth': 4, 'n_estimators': 431, 'subsample': 0.6173641043868554, 'colsample_bytree': 0.7267898695570454}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:50,286] Trial 7 finished with value: 47.78895938207797 and parameters: {'learning_rate': 0.05265439092539168, 'max_depth': 7, 'n_estimators': 354, 'subsample': 0.6113137012827463, 'colsample_bytree': 0.6641713387784474}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:51,619] Trial 8 finished with value: 47.66511999589132 and parameters: {'learning_rate': 0.0765932227760507, 'max_depth': 6, 'n_estimators': 349, 'subsample': 0.8665676370767429, 'colsample_bytree': 0.5904283709434905}. Best is trial 1 with value: 47.43443628392234.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:54,039] Trial 9 finished with value: 47.192769153039244 and parameters: {'learning_rate': 0.035950916005476286, 'max_depth': 10, 'n_estimators': 316, 'subsample': 0.6349234431730602, 'colsample_bytree': 0.7475051430194931}. Best is trial 9 with value: 47.192769153039244.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:55,941] Trial 10 finished with value: 47.7509404446834 and parameters: {'learning_rate': 0.02619020207215901, 'max_depth': 10, 'n_estimators': 226, 'subsample': 0.5082307504570194, 'colsample_bytree': 0.9854788360367821}. Best is trial 9 with value: 47.192769153039244.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:48:57,205] Trial 11 finished with value: 48.165938017863056 and parameters: {'learning_rate': 0.195924276141985, 'max_depth': 10, 'n_estimators': 147, 'subsample': 0.7224257535135079, 'colsample_bytree': 0.8048611342270877}. Best is trial 9 with value: 47.192769153039244.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:00,388] Trial 12 finished with value: 47.17417811334436 and parameters: {'learning_rate': 0.031927016450497746, 'max_depth': 9, 'n_estimators': 496, 'subsample': 0.6891049728160483, 'colsample_bytree': 0.6112921644500462}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:02,193] Trial 13 finished with value: 47.5175850736192 and parameters: {'learning_rate': 0.029400308947256898, 'max_depth': 9, 'n_estimators': 285, 'subsample': 0.7828205339478573, 'colsample_bytree': 0.5621215069637742}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:05,500] Trial 14 finished with value: 47.54991130632125 and parameters: {'learning_rate': 0.03096129651251448, 'max_depth': 9, 'n_estimators': 492, 'subsample': 0.6836331926363207, 'colsample_bytree': 0.8874462415430595}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:07,510] Trial 15 finished with value: 48.547070502415764 and parameters: {'learning_rate': 0.013141459876835586, 'max_depth': 10, 'n_estimators': 206, 'subsample': 0.7967884241172132, 'colsample_bytree': 0.6117370773868174}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:09,464] Trial 16 finished with value: 48.97820975461236 and parameters: {'learning_rate': 0.010258092467989347, 'max_depth': 8, 'n_estimators': 317, 'subsample': 0.6678364849451294, 'colsample_bytree': 0.7212883092184491}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:10,208] Trial 17 finished with value: 49.00484712680179 and parameters: {'learning_rate': 0.03745213571507942, 'max_depth': 6, 'n_estimators': 178, 'subsample': 0.5051961232583999, 'colsample_bytree': 0.8659148241969428}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:12,336] Trial 18 finished with value: 47.70799240920566 and parameters: {'learning_rate': 0.021924005929749364, 'max_depth': 8, 'n_estimators': 403, 'subsample': 0.8431622837360344, 'colsample_bytree': 0.5230838618481022}. Best is trial 12 with value: 47.17417811334436.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:15,283] Trial 19 finished with value: 47.1479103140761 and parameters: {'learning_rate': 0.04424220113768526, 'max_depth': 9, 'n_estimators': 457, 'subsample': 0.9847805547821498, 'colsample_bytree': 0.6179433728808241}. Best is trial 19 with value: 47.1479103140761.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:19,346] Trial 20 finished with value: 47.22665846067137 and parameters: {'learning_rate': 0.05186230413086851, 'max_depth': 9, 'n_estimators': 462, 'subsample': 0.9886301857188453, 'colsample_bytree': 0.6199799331374833}. Best is trial 19 with value: 47.1479103140761.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:22,824] Trial 21 finished with value: 47.031369019917406 and parameters: {'learning_rate': 0.03796305170255731, 'max_depth': 10, 'n_estimators': 463, 'subsample': 0.7450355842343697, 'colsample_bytree': 0.6978969459834861}. Best is trial 21 with value: 47.031369019917406.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:25,945] Trial 22 finished with value: 46.943775379889374 and parameters: {'learning_rate': 0.04096968073164541, 'max_depth': 9, 'n_estimators': 500, 'subsample': 0.763085524400252, 'colsample_bytree': 0.5570455003191673}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:28,463] Trial 23 finished with value: 47.24145992568296 and parameters: {'learning_rate': 0.04081269255272918, 'max_depth': 8, 'n_estimators': 453, 'subsample': 0.9277078633839654, 'colsample_bytree': 0.5544146296735848}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:31,377] Trial 24 finished with value: 47.05462664647447 and parameters: {'learning_rate': 0.06179114819156596, 'max_depth': 10, 'n_estimators': 388, 'subsample': 0.7522432605625006, 'colsample_bytree': 0.6829475764764811}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:34,319] Trial 25 finished with value: 47.70755455228201 and parameters: {'learning_rate': 0.0946088312918985, 'max_depth': 10, 'n_estimators': 404, 'subsample': 0.7618969081403028, 'colsample_bytree': 0.6920907924609323}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:37,509] Trial 26 finished with value: 47.35907100886259 and parameters: {'learning_rate': 0.060511070937104165, 'max_depth': 10, 'n_estimators': 393, 'subsample': 0.8170930449436965, 'colsample_bytree': 0.8083091927269863}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:41,234] Trial 27 finished with value: 49.433464201449134 and parameters: {'learning_rate': 0.17191432508136703, 'max_depth': 10, 'n_estimators': 468, 'subsample': 0.7307953476809058, 'colsample_bytree': 0.6917409305036071}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:42,550] Trial 28 finished with value: 48.95285144081529 and parameters: {'learning_rate': 0.022964901966774028, 'max_depth': 5, 'n_estimators': 434, 'subsample': 0.7625460282130803, 'colsample_bytree': 0.6364614369171945}. Best is trial 22 with value: 46.943775379889374.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:44,453] Trial 29 finished with value: 46.94315861052552 and parameters: {'learning_rate': 0.06240885503798581, 'max_depth': 8, 'n_estimators': 377, 'subsample': 0.822182733104935, 'colsample_bytree': 0.5008595678027121}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:46,582] Trial 30 finished with value: 47.00279151757392 and parameters: {'learning_rate': 0.08442685007562147, 'max_depth': 8, 'n_estimators': 432, 'subsample': 0.9040899254983839, 'colsample_bytree': 0.506248807466039}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:49,795] Trial 31 finished with value: 46.96488149339375 and parameters: {'learning_rate': 0.09194293010488128, 'max_depth': 8, 'n_estimators': 424, 'subsample': 0.8980162271700738, 'colsample_bytree': 0.5044903604544461}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:51,497] Trial 32 finished with value: 47.144088675717384 and parameters: {'learning_rate': 0.0808809811881525, 'max_depth': 7, 'n_estimators': 420, 'subsample': 0.9012661925879311, 'colsample_bytree': 0.5016697707941952}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:53,343] Trial 33 finished with value: 47.39374456715451 and parameters: {'learning_rate': 0.12033676884135057, 'max_depth': 8, 'n_estimators': 378, 'subsample': 0.8917418924581975, 'colsample_bytree': 0.5507463105559924}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:54,720] Trial 34 finished with value: 47.52337528269969 and parameters: {'learning_rate': 0.09260316835433582, 'max_depth': 7, 'n_estimators': 338, 'subsample': 0.8160819567836832, 'colsample_bytree': 0.529790700916964}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:57,282] Trial 35 finished with value: 47.413879477685825 and parameters: {'learning_rate': 0.14320011784445272, 'max_depth': 8, 'n_estimators': 481, 'subsample': 0.9529686212902614, 'colsample_bytree': 0.5018987400961814}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:49:59,391] Trial 36 finished with value: 47.22441808912625 and parameters: {'learning_rate': 0.0685070899118933, 'max_depth': 8, 'n_estimators': 420, 'subsample': 0.8517870511938825, 'colsample_bytree': 0.5827220252291048}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:02,085] Trial 37 finished with value: 47.133117761174084 and parameters: {'learning_rate': 0.09364159589108748, 'max_depth': 9, 'n_estimators': 443, 'subsample': 0.9103675927506059, 'colsample_bytree': 0.5319585233783852}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:03,488] Trial 38 finished with value: 47.71738212323155 and parameters: {'learning_rate': 0.058293123681906214, 'max_depth': 6, 'n_estimators': 377, 'subsample': 0.8811264239865664, 'colsample_bytree': 0.5717666791870267}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:04,940] Trial 39 finished with value: 47.24688075608529 and parameters: {'learning_rate': 0.11342358300600217, 'max_depth': 8, 'n_estimators': 277, 'subsample': 0.8241541193976438, 'colsample_bytree': 0.5412074939908114}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:07,260] Trial 40 finished with value: 47.43511557475472 and parameters: {'learning_rate': 0.13532728808651648, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.9479798136063026, 'colsample_bytree': 0.5093138342340912}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:10,293] Trial 41 finished with value: 47.35548262826277 and parameters: {'learning_rate': 0.0803241875788484, 'max_depth': 9, 'n_estimators': 476, 'subsample': 0.7970662602906194, 'colsample_bytree': 0.5722366220042309}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:12,594] Trial 42 finished with value: 47.439938017019934 and parameters: {'learning_rate': 0.0420523738512031, 'max_depth': 8, 'n_estimators': 427, 'subsample': 0.8419850350146438, 'colsample_bytree': 0.642857214862348}. Best is trial 29 with value: 46.94315861052552.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:15,409] Trial 43 finished with value: 46.928937122939516 and parameters: {'learning_rate': 0.04925959031633168, 'max_depth': 9, 'n_estimators': 451, 'subsample': 0.7231522113107695, 'colsample_bytree': 0.5324314811897863}. Best is trial 43 with value: 46.928937122939516.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:18,134] Trial 44 finished with value: 47.05120887457153 and parameters: {'learning_rate': 0.05359021557986076, 'max_depth': 9, 'n_estimators': 415, 'subsample': 0.7162999659216114, 'colsample_bytree': 0.5901692239947126}. Best is trial 43 with value: 46.928937122939516.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:20,169] Trial 45 finished with value: 47.28541451770178 and parameters: {'learning_rate': 0.07187681075020705, 'max_depth': 7, 'n_estimators': 345, 'subsample': 0.8767126937650097, 'colsample_bytree': 0.5278205878082077}. Best is trial 43 with value: 46.928937122939516.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:21,598] Trial 46 finished with value: 49.555305042267975 and parameters: {'learning_rate': 0.04748750625343355, 'max_depth': 3, 'n_estimators': 441, 'subsample': 0.6615435044339812, 'colsample_bytree': 0.5003952776391422}. Best is trial 43 with value: 46.928937122939516.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:23,693] Trial 47 finished with value: 47.59400071346831 and parameters: {'learning_rate': 0.0943121024394094, 'max_depth': 9, 'n_estimators': 360, 'subsample': 0.5772370395617987, 'colsample_bytree': 0.5517273592279488}. Best is trial 43 with value: 46.928937122939516.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:26,300] Trial 48 finished with value: 47.21194533508662 and parameters: {'learning_rate': 0.0654508842234319, 'max_depth': 8, 'n_estimators': 484, 'subsample': 0.7820757503600066, 'colsample_bytree': 0.5934544328874884}. Best is trial 43 with value: 46.928937122939516.\n<ipython-input-36-383f7fb43152>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n<ipython-input-36-383f7fb43152>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n<ipython-input-36-383f7fb43152>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n[I 2025-02-16 08:50:28,636] Trial 49 finished with value: 47.19914638392174 and parameters: {'learning_rate': 0.08387328572092173, 'max_depth': 9, 'n_estimators': 330, 'subsample': 0.9244306758909008, 'colsample_bytree': 0.5240622033825159}. Best is trial 43 with value: 46.928937122939516.\n","output_type":"stream"},{"name":"stdout","text":"Best parameters: {'learning_rate': 0.04925959031633168, 'max_depth': 9, 'n_estimators': 451, 'subsample': 0.7231522113107695, 'colsample_bytree': 0.5324314811897863}\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\n# Define the model\n# xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\nxgb_model = XGBRegressor(learning_rate=0.049456198506249625, max_depth=10, n_estimators=456, subsample=0.7489727392768031, colsample_bytree=0.5084291551626028, random_state=42)\n# xgb_model = XGBRegressor(learning_rate=0.04925959031633168, max_depth=9, n_estimators=451, subsample=0.7489727392768031, colsample_bytree=0.5084291551626028, random_state=42)\n# 'learning_rate': 0.049456198506249625, 'max_depth': 10, 'n_estimators': 456, 'subsample': 0.7489727392768031, 'colsample_bytree': 0.5084291551626028\n# 'learning_rate': 0.04925959031633168, 'max_depth': 9, 'n_estimators': 451, 'subsample': 0.7231522113107695, 'colsample_bytree': 0.5324314811897863\n# Train the model\nxgb_model.fit(X_train_processed, y_train)\n\nr2score, rmse = r2score_and_rmse(xgb_model, X_train_processed, y_train)\nprint('\\nR2 score (on training data, best=1):', r2score)\nprint(\"Root Mean Square Error: \", rmse.round(decimals=1))\nstore_model(model, model_name=\"XGBoost_tryagain\")\n# Predict labels for some training instances:\nprint(\"\\nPredictions: \", xgb_model.predict(X_train_processed[0:9]).round(decimals=1))\nprint(\"Labels:      \", list(y_train[0:9]))\n\n# # Make predictions\n# y_pred = xgb_model.predict(X_test)\n\n# # Evaluate performance\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# print(\"RMSE:\", rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T09:08:03.879230Z","iopub.execute_input":"2025-02-16T09:08:03.879531Z","iopub.status.idle":"2025-02-16T09:08:08.994992Z","shell.execute_reply.started":"2025-02-16T09:08:03.879509Z","shell.execute_reply":"2025-02-16T09:08:08.993931Z"}},"outputs":[{"name":"stdout","text":"\nR2 score (on training data, best=1): 0.6541787963168783\nRoot Mean Square Error:  36.0\n\nPredictions:  [175.2  89.5  80.4  77.1 114.4  94.2 233.5  79.7  72.9]\nLabels:       [351.43, 94.23, 69.7, 84.44, 75.76, 93.75, 464.29, 78.57, 71.21]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"#%% 5.5 EVALUATE MODELS\nfrom sklearn.model_selection import cross_val_score\nprint('\\n____________ K-fold cross validation ____________')\nrun_new_evaluation = True\nif run_new_evaluation:\n    cv = KFold(n_splits=5,shuffle=True,random_state=37) \n\n    # Evaluate LinearRegression:\n    model_name = \"LinearRegression\" \n    model = LinearRegression()             \n    nmse_scores = cross_val_score(model, X_train_processed, y_train, cv=cv, scoring='neg_mean_squared_error')\n    rmse_scores = np.sqrt(-nmse_scores)\n    joblib.dump(rmse_scores,'/kaggle/working/' + model_name + '_rmse.pkl')\n    print(\"LinearRegression rmse: \", rmse_scores.round(decimals=1))\n    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n\n    # Evaluate DecisionTreeRegressor:\n    model_name = \"DecisionTreeRegressor\" \n    model = DecisionTreeRegressor()\n    nmse_scores = cross_val_score(model, X_train_processed, y_train, cv=cv, scoring='neg_mean_squared_error')\n    rmse_scores = np.sqrt(-nmse_scores)\n    joblib.dump(rmse_scores,'/kaggle/working/' + model_name + '_rmse.pkl')\n    print(\"DecisionTreeRegressor rmse: \", rmse_scores.round(decimals=1))\n    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n\n    # Evaluate RandomForestRegressor:\n    model_name = \"RandomForestRegressor\" \n    model = RandomForestRegressor(n_estimators = 5)\n    nmse_scores = cross_val_score(model, X_train_processed, y_train, cv=cv, scoring='neg_mean_squared_error')\n    rmse_scores = np.sqrt(-nmse_scores)\n    joblib.dump(rmse_scores,'/kaggle/working/' + model_name + '_rmse.pkl')\n    print(\"RandomForestRegressor rmse: \", rmse_scores.round(decimals=1))\n    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n\n    # Evaluate XGBoost\n    model_name = \"XGBoost\" \n    model = XGBRegressor(learning_rate=0.049456198506249625, max_depth=10, n_estimators=456, subsample=0.7489727392768031, colsample_bytree=0.5084291551626028, random_state=42)\n    nmse_scores = cross_val_score(model, X_train_processed, y_train, cv=cv, scoring='neg_mean_squared_error')\n    rmse_scores = np.sqrt(-nmse_scores)\n    joblib.dump(rmse_scores,'/kaggle/working/' + model_name + '_rmse.pkl')\n    print(\"XGBoost rmse: \", rmse_scores.round(decimals=1))\n    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:53:16.539772Z","iopub.execute_input":"2025-02-16T08:53:16.540477Z","iopub.status.idle":"2025-02-16T08:55:14.876466Z","shell.execute_reply.started":"2025-02-16T08:53:16.540420Z","shell.execute_reply":"2025-02-16T08:55:14.874431Z"}},"outputs":[{"name":"stdout","text":"\n____________ K-fold cross validation ____________\nLinearRegression rmse:  [46.5 51.7 51.  52.8 51.6]\nAvg. rmse:  50.72 \n\nDecisionTreeRegressor rmse:  [58.8 59.4 61.7 59.6 59.7]\nAvg. rmse:  59.84 \n\nRandomForestRegressor rmse:  [47.9 51.4 51.8 51.1 50.4]\nAvg. rmse:  50.519999999999996 \n\nXGBoost rmse:  [40.9 47.1 45.7 46.6 45. ]\nAvg. rmse:  45.06 \n\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# In[7]: PART 7. ANALYZE AND TEST THE BEST MODEL\n#region:\n# 7.1 Pick the best model (random forest):\nsearch = joblib.load('/kaggle/working/RandomForestRegressor_randsearch.pkl')\nbest_model = search.best_estimator_\n# best_model = joblib.load('/kaggle/working/RandomForestRegressor_model.pkl')\n# 7.2 Analyse the solution to get more insights about the data:\n# NOTE: ONLY for rand forest\nprint('\\n____________ ANALYZE AND TEST YOUR SOLUTION ____________')\nprint('SOLUTION: ' , best_model)\nstore_model(best_model, model_name=\"SOLUTION\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% 7.3 Run on test data:\n# full_pipeline = joblib.load(r'/kaggle/working/full_pipeline.pkl')\nbest_model = joblib.load(r'/kaggle/working/SOLUTION_model.pkl')\nbest_model.fit(X_train_processed, y_train)\n# processed_test_set = full_pipeline.transform(test_set)  \n# Compute R2 score and root mean squared error:\nr2score, rmse = r2score_and_rmse(best_model, X_test_processed, y_test)\nprint('\\nPerformance on test data:')\nprint('R2 score (on test data, best=1):', r2score)\nprint(\"Root Mean Square Error: \", rmse.round(decimals=1))\n# Predict labels for some test instances:\nprint(\"\\nTest data: \\n\", X_test.iloc[0:9])\nprint(\"\\nProcessed_test_set: \\n\", X_test_processed[0:9])\nprint(\"\\nPredictions: \", best_model.predict(X_test_processed[0:9]).round(decimals=1))\nprint(\"Labels:      \", list(y_test[0:9]),'\\n')\n\n#endregion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T09:12:43.988346Z","iopub.execute_input":"2025-02-16T09:12:43.988648Z","iopub.status.idle":"2025-02-16T09:12:48.264124Z","shell.execute_reply.started":"2025-02-16T09:12:43.988624Z","shell.execute_reply":"2025-02-16T09:12:48.262261Z"}},"outputs":[{"name":"stdout","text":"\nPerformance on test data:\nR2 score (on test data, best=1): 0.4457226119202897\nRoot Mean Square Error:  46.8\n\nTest data: \n                     Quận               Huyện        Loại hình nhà ở  \\\n6658      Quận Hoàng Mai      Phường Đại Kim           Nhà ngõ, hẻm   \n54854       Quận Hà Đông     Phường Vạn Phúc           Nhà ngõ, hẻm   \n5013      Quận Hoàng Mai   Phường Thịnh Liệt           Nhà ngõ, hẻm   \n13466        Quận Tây Hồ    Phường Thụy Khuê           Nhà ngõ, hẻm   \n18698   Quận Bắc Từ Liêm    Phường Cổ Nhuế 2  Nhà mặt phố, mặt tiền   \n76040     Quận Hoàng Mai     Phường Giáp Bát  Nhà mặt phố, mặt tiền   \n2054      Quận Hoàng Mai    Phường Tương Mai           Nhà ngõ, hẻm   \n8703   Quận Hai Bà Trưng    Phường Quỳnh Mai           Nhà ngõ, hẻm   \n75895     Huyện Hoài Đức  Thị trấn Trạm Trôi           Nhà biệt thự   \n\n      Giấy tờ pháp lý  Số tầng  Số phòng ngủ  Diện tích  Dài (m)  Rộng (m)  \n6658              NaN      NaN           3.0       33.0      NaN       8.0  \n54854        Đã có sổ      NaN           3.0       32.0      NaN       NaN  \n5013         Đã có sổ      5.0           3.0       28.0      9.0       3.2  \n13466        Đã có sổ      5.0           3.0       32.0      NaN       NaN  \n18698        Đã có sổ      NaN           4.0       70.0      NaN       NaN  \n76040             NaN      NaN           4.0       60.0      NaN       4.0  \n2054         Đã có sổ      4.0           4.0       40.0      NaN       4.0  \n8703         Đã có sổ      NaN           3.0       40.0      NaN       NaN  \n75895        Đã có sổ      NaN           8.0      350.0     25.0      13.0  \n\nProcessed_test_set: \n   (0, 0)\t0.2279200325294349\n  (0, 1)\t-0.6127130015493906\n  (0, 2)\t-0.2853606825517204\n  (0, 3)\t-0.006286675912486139\n  (0, 4)\t-0.00578056175934251\n  (0, 25)\t1.0\n  (0, 194)\t1.0\n  (0, 326)\t1.0\n  (0, 329)\t1.0\n  (1, 0)\t0.2279200325294349\n  (1, 1)\t-0.6127130015493906\n  (1, 2)\t-0.3058804697451515\n  (1, 3)\t-0.006286675912486139\n  (1, 4)\t-0.007522523275535914\n  (1, 26)\t1.0\n  (1, 180)\t1.0\n  (1, 326)\t1.0\n  (1, 331)\t1.0\n  (2, 0)\t0.2279200325294349\n  (2, 1)\t-0.6127130015493906\n  (2, 2)\t-0.38795961851887567\n  (2, 3)\t-0.006565916046458385\n  (2, 4)\t-0.007870915578774595\n  (2, 25)\t1.0\n  (2, 151)\t1.0\n  :\t:\n  (6, 2)\t-0.1417221721977031\n  (6, 3)\t-0.006286675912486139\n  (6, 4)\t-0.007522523275535914\n  (6, 25)\t1.0\n  (6, 170)\t1.0\n  (6, 326)\t1.0\n  (6, 331)\t1.0\n  (7, 0)\t0.2279200325294349\n  (7, 1)\t-0.6127130015493906\n  (7, 2)\t-0.1417221721977031\n  (7, 3)\t-0.006286675912486139\n  (7, 4)\t-0.007522523275535914\n  (7, 23)\t1.0\n  (7, 138)\t1.0\n  (7, 326)\t1.0\n  (7, 331)\t1.0\n  (8, 0)\t0.2279200325294349\n  (8, 1)\t3.216772889861461\n  (8, 2)\t6.219411857765921\n  (8, 3)\t-0.0020980739029024596\n  (8, 4)\t-0.0036031098641007542\n  (8, 8)\t1.0\n  (8, 213)\t1.0\n  (8, 324)\t1.0\n  (8, 331)\t1.0\n\nPredictions:  [ 87.4  78.2  89.3 103.5  99.  108.   76.9  96.5  59.6]\nLabels:       [83.33, 75.0, 105.36, 95.31, 192.86, 121.67, 65.0, 85.0, 37.14] \n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":53}]}